{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moriarty, D., Schultz, A. & Grefenstette, J. (1999). Evolutionary Algorithms for Reinforcement Learning. Journal of Artificial Intelligence Research, 11, 241-276. https://doi.org/10.1613/jair.613 - A Review on the use of Evolutionary Algorithms in Reinforcement Learning, something that, apparently, was relatively popular in the 1990s.\n",
    "\n",
    "Bai, H., Cheng, R. & Jin, Y. (2023). Evolutionary Reinforcement Learning: A Survey. Intelligent Computing, 2, Article 0025. https://doi.org/10.34133/icomputing.0025  - Yet another review. There is a vast range of uses for Evolutionary Algorithms in RL, not just the model to be used, but even the epsilon hyperparameter, and the reward function.\n",
    "\n",
    "https://lilianweng.github.io/posts/2018-02-19-rl-overview/#evolution-strategies - Lil's Log, by Lilian Weng\n",
    "\n",
    "\"ES, as a black-box optimization algorithm, is another approach to RL problems (In my original writing, I used the phrase “a nice alternative”; Seita pointed me to this discussion and thus I updated my wording.)\" - Lil's Log\n",
    "\n",
    "Unfortunately, it seems that nowadays Evolutionary Algorithms for Reinforcement Learning tend to make people a bit...nervous.\n",
    "\n",
    "Evolutionary Algorithms are, afterall, less efficient than gradient optimization.\n",
    "\n",
    "Even so, I like the idea of Evolutionary Algorithms, so let's play a bit. Let's stick to the simple idea of selecting the most fitting subject (\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subject(nn.Module):\n",
    "\n",
    "    '''\n",
    "    Simple Neural Network for testing\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # No epsilon, no mode.\n",
    "        # Each subject shall prove its worthness\n",
    "\n",
    "        super(Subject, self).__init__()\n",
    "\n",
    "        # Input = 3x200x256\n",
    "\n",
    "        self.neuron1 = nn.Linear(3*200*256, 64)\n",
    "        self.neuron2 = nn.Linear(64, 64)\n",
    "        self.neuron3 = nn.Linear(64, 12)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Our environment is MultiBinary, so we'll use Sigmoid.\n",
    "        # MultiBinary Environment: For each button, determine if pressed or not.\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, obs):\n",
    "\n",
    "        x = obs.contiguous().view(obs.size(0), -1)\n",
    "\n",
    "        x = self.neuron1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.neuron2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        actions = self.neuron3(x)\n",
    "\n",
    "        actions = self.sigmoid(actions)\n",
    "\n",
    "        del x\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitution_gaussian_mutation(gene, n_mutations):\n",
    "\n",
    "    mean, std = torch.mean(gene), torch.std(gene)\n",
    "\n",
    "    try:\n",
    "\n",
    "        distribution = torch.distributions.Normal(mean, std)\n",
    "\n",
    "    except: # If standard deviation is invalid (0.0), use Normal Distribution instead\n",
    "\n",
    "        distribution = torch.distributions.Normal(torch.zeros(1,), torch.ones(1,))\n",
    "\n",
    "    for mutate in range(n_mutations):\n",
    "\n",
    "        if gene.ndim == 1: # Bias\n",
    "\n",
    "            element = torch.randperm(gene.size(0))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[element] = mutation\n",
    "\n",
    "        elif gene.ndim == 2: # Linear Layer\n",
    "\n",
    "            row, column = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[row, column] = mutation\n",
    "\n",
    "        else: # Convolution Layer\n",
    "\n",
    "            A, B, C, D = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item(), torch.randperm(gene.size(2))[0].item(), torch.randperm(gene.size(3))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[A, B, C, D] = mutation\n",
    "\n",
    "    return gene\n",
    "\n",
    "def substitution_normal_mutation(gene, n_mutations):\n",
    "\n",
    "    distribution = torch.distributions.Normal(torch.zeros(1,), torch.ones(1,))\n",
    "\n",
    "    for mutate in range(n_mutations):\n",
    "\n",
    "        if gene.ndim == 1: # Bias\n",
    "\n",
    "            element = torch.randperm(gene.size(0))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[element] = mutation\n",
    "\n",
    "        elif gene.ndim == 2: # Linear Layer\n",
    "\n",
    "            row, column = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[row, column] = mutation\n",
    "\n",
    "        else: # Convolution Layer\n",
    "\n",
    "            A, B, C, D = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item(), torch.randperm(gene.size(2))[0].item(), torch.randperm(gene.size(3))[0].item()\n",
    "\n",
    "            mutation = distribution.sample((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[A, B, C, D] = mutation\n",
    "\n",
    "    return gene\n",
    "\n",
    "def deletion_mutation(gene, n_mutations):\n",
    "\n",
    "    for mutate in range(n_mutations):\n",
    "\n",
    "        if gene.ndim == 1: # Bias\n",
    "\n",
    "            element = torch.randperm(gene.size(0))[0].item()\n",
    "\n",
    "            mutation = torch.zeros((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[element] = mutation\n",
    "\n",
    "        elif gene.ndim == 2: # Linear Layer\n",
    "\n",
    "            row, column = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item()\n",
    "\n",
    "            mutation = torch.zeros((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[row, column] = mutation\n",
    "\n",
    "        else: # Convolution Layer\n",
    "\n",
    "            A, B, C, D = torch.randperm(gene.size(0))[0].item(), torch.randperm(gene.size(1))[0].item(), torch.randperm(gene.size(2))[0].item(), torch.randperm(gene.size(3))[0].item()\n",
    "\n",
    "            mutation = torch.zeros((1,))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[A, B, C, D] = mutation\n",
    "\n",
    "    return gene\n",
    "\n",
    "def inversion_mutation(gene, n_mutations):\n",
    "\n",
    "    for mutate in range(n_mutations):\n",
    "\n",
    "        if gene.ndim == 1: # Bias\n",
    "\n",
    "            elements = torch.randperm(gene.size(0))\n",
    "\n",
    "            mutationA = gene[elements[0]].clone()\n",
    "            mutationB = gene[elements[1]].clone()\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                gene[elements[0].item()] = mutationB\n",
    "                gene[elements[1].item()] = mutationA\n",
    "\n",
    "        elif gene.ndim == 2: # Linear Layer\n",
    "\n",
    "            rows, columns = torch.randperm(gene.size(0)), torch.randperm(gene.size(1))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                mutationA = gene[rows[0].item(), columns[0].item()].clone()\n",
    "                mutationB = gene[rows[1].item(), columns[1].item()].clone()\n",
    "\n",
    "                gene[rows[0].item(), columns[0].item()] = mutationB\n",
    "                gene[rows[1].item(), columns[1].item()] = mutationA\n",
    "\n",
    "        else: # Convolution Layer\n",
    "\n",
    "            A, B, C, D = torch.randperm(gene.size(0)), torch.randperm(gene.size(1)), torch.randperm(gene.size(2)), torch.randperm(gene.size(3))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                mutationA = gene[A[0].item(), B[0].item(), C[0].item(), D[0].item()].clone()\n",
    "                mutationB = gene[A[1].item(), B[1].item(), C[1].item(), D[1].item()].clone()\n",
    "\n",
    "                gene[A[0].item(), B[0].item(), C[0].item(), D[0].item()] = mutationB\n",
    "                gene[A[1].item(), B[1].item(), C[1].item(), D[1].item()] = mutationA\n",
    "\n",
    "    return gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "POPULATION_SIZE = 20\n",
    "MUTAGEN_FACTOR = 100 # The maximum number of mutated genes\n",
    "GENERATIONS = 5 # During how many generations Selection will be applied\n",
    "# Note: 1 Generation = 1 Epoch --> 1 complete iteration through entire dataset\n",
    "GENERATION_SIZE = 1000 # How many iterations configure a single generation --> Timesteps\n",
    "GAMMA = 0.99 # Discount factor for future rewards (uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "6\n",
      "neuron1.weight\n"
     ]
    }
   ],
   "source": [
    "population = [Subject().to(device) for i in range(POPULATION_SIZE)]\n",
    "chromossomes = [x.state_dict() for x in population]\n",
    "genes = [n for n, _ in population[0].named_parameters()]\n",
    "\n",
    "print(len(chromossomes))\n",
    "#print(chromossomes[0]) # 50 chromossomes -> Used to map each gene\n",
    "print(len(genes)) # 6 genes per subject -> The neuron weights + biases\n",
    "print(genes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5\n",
      "Best model so far: 1\n",
      "Best Model Total Reward: 1.5085072845977265e-05\n",
      "2/5\n",
      "Best model so far: 0\n",
      "Best Model Total Reward: 494.9991455078125\n",
      "3/5\n",
      "Best model so far: 19\n",
      "Best Model Total Reward: -22.458486557006836\n",
      "4/5\n",
      "Best model so far: 19\n",
      "Best Model Total Reward: -22.458486557006836\n",
      "5/5\n",
      "Best model so far: 0\n",
      "Best Model Total Reward: 13.07724380493164\n"
     ]
    }
   ],
   "source": [
    "# Do the Evolution\n",
    "\n",
    "# Gym doesn't allow for multiple instances, but let's see if we can fool it\n",
    "env = retro.make(game=\"StreetFighterIISpecialChampionEdition-Genesis\", state=\"ChunLiVsBlanka.1star\")\n",
    "environments = [env]*POPULATION_SIZE\n",
    "states = [x.reset() for x in environments]\n",
    "obs = env.reset()\n",
    "obs = torch.from_numpy(obs)\n",
    "obs = obs/255\n",
    "obs = obs.permute(2, 1, 0).unsqueeze(0).float().to(device)\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "\n",
    "    rewards = [[0.0]]*POPULATION_SIZE\n",
    "\n",
    "    MUTAGEN_FACTOR = MUTAGEN_FACTOR//(2 ** generation)\n",
    "\n",
    "    if MUTAGEN_FACTOR <= 1:\n",
    "\n",
    "        MUTAGEN_FACTOR = 2\n",
    "\n",
    "    for _ in range(GENERATION_SIZE):\n",
    "\n",
    "        for subject in range(POPULATION_SIZE):\n",
    "\n",
    "            obs = states[subject]\n",
    "            obs = torch.from_numpy(obs)\n",
    "            obs = obs/255\n",
    "            obs = obs.permute(2, 1, 0).unsqueeze(0).float().to(device)\n",
    "\n",
    "            with torch.no_grad(): # No grads since we're not using Gradient Descent\n",
    "\n",
    "                action = population[subject](obs)\n",
    "                action = action.squeeze(0)\n",
    "\n",
    "            # MultiBinary Environment --> Only 0.0 or 1.0 accepted\n",
    "            bin = []\n",
    "            for x in action:\n",
    "                if x > 0.5:\n",
    "                    bin.append(1.)\n",
    "                else:\n",
    "                    bin.append(0.)\n",
    "            \n",
    "            action = bin # This is the actual action\n",
    "\n",
    "            obs, reward, end, info = environments[subject].step(action)\n",
    "            states[subject] = obs\n",
    "\n",
    "            reward = (info['health']**(1+info['matches_won'])) - (info['enemy_health']**(1+info['enemy_matches_won']))\n",
    "            reward = torch.tensor(reward, device=device)\n",
    "            reward = -(10.0/(torch.exp(reward) + 1.0)) + 5.0 # Normalizing to -5 to +5 (sigmoid function)\n",
    "            \n",
    "            rewards[subject].append(reward)\n",
    "\n",
    "    for subject_reward_t in range(len(rewards)):\n",
    "\n",
    "        subject_reward = rewards[subject_reward_t]\n",
    "\n",
    "        for r_t in range(len(subject_reward)):\n",
    "\n",
    "            subject_reward[r_t] = subject_reward[r_t] * (GAMMA ** r_t)\n",
    "\n",
    "        # Getting the total (discounted) reward\n",
    "\n",
    "        subject_reward = torch.tensor(subject_reward)\n",
    "        subject_reward = subject_reward.sum()\n",
    "\n",
    "        rewards[subject_reward_t] = subject_reward.item()\n",
    "\n",
    "    #rewards = [rewards[i][0] for i in range(len(rewards))]\n",
    "    rewards = torch.tensor(rewards)\n",
    "\n",
    "    rewards, idx = torch.sort(rewards, descending=True)\n",
    "\n",
    "    # Selecting the 10 most fit subjects to reproduce (through mitosis)\n",
    "    # And applying mutations\n",
    "\n",
    "    for s in range(10):\n",
    "\n",
    "        population[idx[POPULATION_SIZE-1-s].item()] = deepcopy(population[idx[s].item()])\n",
    "\n",
    "        # Selecting genes for mutation ---> Genes = weights and biases\n",
    "\n",
    "        selected_gene = torch.randint(0, len(genes), (1,)).item()\n",
    "        gene = genes[selected_gene]\n",
    "        gene = [chromossomes[idx[POPULATION_SIZE-1-s].item()][gene]]\n",
    "\n",
    "        chance = abs(torch.rand((1,)))\n",
    "\n",
    "        if 0.0 < chance < 0.3:\n",
    "\n",
    "            n_mutations = torch.randint(1, MUTAGEN_FACTOR, (1,)).item()\n",
    "\n",
    "            for codon in gene:\n",
    "\n",
    "                substitution_gaussian_mutation(codon, n_mutations)\n",
    "\n",
    "        if 0.3 < chance < 0.4:\n",
    "\n",
    "            n_mutations = torch.randint(1, MUTAGEN_FACTOR, (1,)).item()\n",
    "\n",
    "            for codon in gene:\n",
    "\n",
    "                substitution_normal_mutation(codon, n_mutations)\n",
    "\n",
    "        if 0.4 < chance < 0.5:\n",
    "\n",
    "            n_mutations = torch.randint(1, MUTAGEN_FACTOR, (1,)).item()\n",
    "\n",
    "            for codon in gene:\n",
    "\n",
    "                deletion_mutation(codon, n_mutations)\n",
    "\n",
    "        if 0.5 < chance < 0.8:\n",
    "\n",
    "            n_mutations = torch.randint(1, MUTAGEN_FACTOR, (1,)).item()\n",
    "\n",
    "            for codon in gene:\n",
    "\n",
    "                inversion_mutation(codon, n_mutations)\n",
    "\n",
    "    print(f\"{generation+1}/{GENERATIONS}\")\n",
    "    print(f\"Best model so far: {idx[0].item()}\")\n",
    "    print(f\"Best Model Total Reward: {rewards[0]}\")\n",
    "\n",
    "for e in environments:\n",
    "\n",
    "    e.close()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gameplay Mode\n",
    "\n",
    "env = retro.make(game=\"StreetFighterIISpecialChampionEdition-Genesis\", state=\"ChunLiVsBlanka.1star\")\n",
    "obs = env.reset()\n",
    "obs = torch.from_numpy(obs)\n",
    "obs = obs/255\n",
    "obs = obs.permute(2, 1, 0).unsqueeze(0).float().to(device)\n",
    "steps = 0\n",
    "\n",
    "best_model = population[idx[0].item()]\n",
    "\n",
    "# If you'd like to save and train even more\n",
    "\n",
    "'''states = []\n",
    "actions = []\n",
    "rewards = []\n",
    "deltas = []'''\n",
    "\n",
    "while steps < 1000:\n",
    "    env.render()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        action = best_model(obs)\n",
    "\n",
    "    action = action.squeeze(0)\n",
    "\n",
    "    # MultiBinary Environment --> Only 0.0 or 1.0 accepted\n",
    "    bin = []\n",
    "    for x in action:\n",
    "        if x > 0.5:\n",
    "            bin.append(1.)\n",
    "        else:\n",
    "            bin.append(0.)\n",
    "\n",
    "    action = bin\n",
    "\n",
    "    obs, reward, end, info = env.step(action)\n",
    "    obs = torch.from_numpy(obs)\n",
    "    obs = obs/255\n",
    "    obs = obs.permute(2, 1, 0).unsqueeze(0).float().to(device)\n",
    "    #reward = torch.tensor(reward, device=device)\n",
    "\n",
    "    '''reward = (info['health']**(1+info['matches_won'])) - (info['enemy_health']**(1+info['enemy_matches_won']))\n",
    "    reward = torch.tensor(reward, device=device)\n",
    "    reward = -(10.0/(torch.exp(reward) + 1.0)) + 5.0 # Normalizing to -5 to +5 (sigmoid function)'''\n",
    "\n",
    "    '''states.append(obs.cpu())\n",
    "    actions.append(action.cpu())\n",
    "    rewards.append(reward.cpu())\n",
    "    deltas.append(delta.cpu())'''\n",
    "\n",
    "    steps += 1\n",
    "\n",
    "env.render(close=True)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
